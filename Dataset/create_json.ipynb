{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 13068549,
     "sourceType": "datasetVersion",
     "datasetId": 8276365
    },
    {
     "sourceId": 13348321,
     "sourceType": "datasetVersion",
     "datasetId": 8465272
    },
    {
     "sourceId": 13348524,
     "sourceType": "datasetVersion",
     "datasetId": 8465432
    },
    {
     "sourceId": 13348605,
     "sourceType": "datasetVersion",
     "datasetId": 8465499
    },
    {
     "sourceId": 13358278,
     "sourceType": "datasetVersion",
     "datasetId": 8472986
    },
    {
     "sourceId": 13366161,
     "sourceType": "datasetVersion",
     "datasetId": 8478878
    },
    {
     "sourceId": 13366329,
     "sourceType": "datasetVersion",
     "datasetId": 8479006
    },
    {
     "sourceId": 13386265,
     "sourceType": "datasetVersion",
     "datasetId": 8493856
    },
    {
     "sourceId": 13390646,
     "sourceType": "datasetVersion",
     "datasetId": 8496842
    },
    {
     "sourceId": 13498360,
     "sourceType": "datasetVersion",
     "datasetId": 8570464
    }
   ],
   "dockerImageVersionId": 31089,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import ast\n",
    "import re\n",
    "from typing import List, Tuple, Dict\n",
    "import pandas as pd\n",
    "\n",
    "def tokenize_and_label(text: str, subs: Dict[str,str]) -> Tuple[List[str], List[str]]:\n",
    "    pl2lbl = {\n",
    "        \"<author_clinical_condition>\":\"CLIN_COND\",\n",
    "        \"<author_medical_report>\":   \"MED_REP\",\n",
    "        \"<author_genetic>\":          \"GENETIC\",\n",
    "        \"<author_fertility>\":        \"FERTILITY\",\n",
    "        \"<author_disability>\":       \"DISABILITY\",\n",
    "        \"<author_addiction>\":        \"ADDICTION\"\n",
    "    }\n",
    "    \n",
    "    char_labels = [\"O\"] * len(text)\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    for ph, real in subs.items():\n",
    "        lbl = pl2lbl.get(ph)\n",
    "        if not lbl:\n",
    "            continue\n",
    "        real = str(real)\n",
    "        real_lower = real.lower()\n",
    "\n",
    "        if not real or real.strip() == \"\":\n",
    "            continue\n",
    "        \n",
    "        start = 0\n",
    "        while True:\n",
    "            start = text_lower.find(real_lower, start)\n",
    "            if start < 0:\n",
    "                break\n",
    "            \n",
    "            for i in range(start, start + len(real)):\n",
    "                char_labels[i] = \"I-\" + lbl\n",
    "            char_labels[start] = \"B-\" + lbl\n",
    "            \n",
    "            start += len(real)  \n",
    "    \n",
    "    tokens, labels = [], []\n",
    "    for m in re.finditer(r\"\\S+\", text):\n",
    "        tok = m.group()\n",
    "        start = m.start()\n",
    "        lbl = char_labels[start]\n",
    "        \n",
    "        if lbl == \"O\":\n",
    "            for i in range(start, m.end()):\n",
    "                if char_labels[i].startswith(\"B-\"):\n",
    "                    lbl = char_labels[i]\n",
    "                    break\n",
    "        \n",
    "        if lbl.startswith(\"I-\") and (start == 0 or char_labels[start-1] != lbl):\n",
    "            lbl = \"B-\" + lbl.split(\"-\",1)[1]\n",
    "        \n",
    "        if tok and tok[-1] in \"?.!:;,()[]'\":\n",
    "            tok = tok[:-1]\n",
    "        \n",
    "        tokens.append(tok)\n",
    "        labels.append(lbl)\n",
    "    \n",
    "    return tokens, labels\n",
    "\n",
    "def save_to_json(records: List[Dict], filename: str):\n",
    "    dataset_structure = {\n",
    "        \"DatasetDict\": {\n",
    "            \"medical_consultations\": {\n",
    "                \"Dataset\": {\n",
    "                    \"features\": [\"tokens\", \"ent_tags\"],\n",
    "                    \"num_rows\": len(records),\n",
    "                    \"data\": records\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(dataset_structure, f, indent=2, ensure_ascii=False)"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-25T14:16:49.411326Z",
     "iopub.execute_input": "2025-10-25T14:16:49.412123Z",
     "iopub.status.idle": "2025-10-25T14:16:49.423491Z",
     "shell.execute_reply.started": "2025-10-25T14:16:49.412084Z",
     "shell.execute_reply": "2025-10-25T14:16:49.422507Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "aggregated_records = []\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/dataset-training-ner/dataset_with_only_medical_pii.csv')\n",
    "\n",
    "for i in range(1002):\n",
    "    final_text = df['final_text'][i]\n",
    "    if isinstance(final_text, float):\n",
    "        print(\"final_text è float. È NaN?\", pd.isna(final_text))\n",
    "        continue\n",
    "        \n",
    "    substitutions_dictionary = df['substitutions_dictionary'][i]\n",
    "    \n",
    "    try:\n",
    "        subs = ast.literal_eval(substitutions_dictionary)\n",
    "    except Exception as e:\n",
    "        try:\n",
    "            subs = json.loads(substitutions_dictionary)\n",
    "        except Exception as e2:\n",
    "            raise ValueError(\"Impossibile convertire la stringa in dict\")\n",
    "\n",
    "    tokens, labels = tokenize_and_label(final_text, subs)\n",
    "\n",
    "    aggregated_records.append({\n",
    "                \"tokens\": tokens,\n",
    "                \"ent_tags\": labels\n",
    "            })\n",
    "\n",
    "save_to_json(aggregated_records, \"medical_dataset_NER.json\")\n",
    "print(\"Dataset per NER creato con successo.\")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-25T14:16:53.777865Z",
     "iopub.execute_input": "2025-10-25T14:16:53.778588Z",
     "iopub.status.idle": "2025-10-25T14:16:53.973923Z",
     "shell.execute_reply.started": "2025-10-25T14:16:53.778558Z",
     "shell.execute_reply": "2025-10-25T14:16:53.972626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Dataset per NER creato con successo.\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 9
  }
 ]
}
